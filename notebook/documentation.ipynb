{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation - Climate Change in France Visualisation\n",
    "\n",
    "The goal of this notebook is to showcase the data sources as well as the process of data transformation related to the databases in order to construct the data visualisation dashboard in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Données changement climatique - Longues Séries Homogénéisées\n",
    "\n",
    "[Source Page](https://www.data.gouv.fr/en/datasets/donnees-changement-climatique-lsh-longues-series-homogeneisees/#/resources)\n",
    "\n",
    "Variables:\n",
    "\n",
    "- TN: Température minimale/Minimal temperature\n",
    "- TX: Température maximale/Maximal temperature\n",
    "- RR: Précipitations/Precipitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSH_SOURCES = {\n",
    "    \"RR\": {\n",
    "        \"dataset\": \"https://www.data.gouv.fr/fr/datasets/r/76fd5cf2-d936-47ca-b7a5-a4b6cc081963\",\n",
    "        \"list\": \"https://www.data.gouv.fr/fr/datasets/r/4aa508b1-d7a8-48c4-a8de-6e76b8641cf6\",\n",
    "    },\n",
    "    \"TN\": {\n",
    "        \"dataset\": \"https://www.data.gouv.fr/fr/datasets/r/f42d8312-1b56-4685-81a7-43f3fd3e12e9\",\n",
    "        \"list\": \"https://www.data.gouv.fr/fr/datasets/r/e2fb0be7-1d32-4f44-944d-e97e5961ce5d\",\n",
    "    },\n",
    "    \"TX\": {\n",
    "        \"dataset\": \"https://www.data.gouv.fr/fr/datasets/r/6c47e287-d1d0-4430-9f1a-c0d4f06e77c3\",\n",
    "        \"list\": \"https://www.data.gouv.fr/fr/datasets/r/f6382e83-c207-4e33-b413-4d6acbb08bf4\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "if not RAW_DIR.exists():\n",
    "    RAW_DIR.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSH_DIR = RAW_DIR / \"LSH\"\n",
    "LSH_ZIP_DIR = LSH_DIR / \"zip\"\n",
    "if not LSH_ZIP_DIR.exists():\n",
    "    LSH_ZIP_DIR.mkdir(parents=True)\n",
    "\n",
    "for k, v in LSH_SOURCES.items():\n",
    "    # Create directory\n",
    "    dir_name = k\n",
    "\n",
    "    dataset_dir = LSH_DIR / dir_name\n",
    "    dataset_list_dir = LSH_DIR / \"list\"\n",
    "    if not dataset_list_dir.exists():\n",
    "        dataset_list_dir.mkdir()\n",
    "    if dataset_dir.exists():\n",
    "        continue\n",
    "    dataset_dir.mkdir()\n",
    "\n",
    "    # Download datasets\n",
    "    url = v[\"dataset\"]\n",
    "    r = requests.get(url)\n",
    "    with open(LSH_ZIP_DIR / f\"{k}.zip\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    # Unzip\n",
    "    with ZipFile(LSH_ZIP_DIR / f\"{k}.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dataset_dir)\n",
    "\n",
    "    # Download list\n",
    "    url = v[\"list\"]\n",
    "    r = requests.get(url)\n",
    "    with open(dataset_list_dir / f\"list_{k}.csv\", \"wb\") as f:\n",
    "        f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Metadata on Meterological Stations\n",
    "\n",
    "[Source Page](https://www.data.gouv.fr/en/datasets/informations-sur-les-stations-metadonnees/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_DIR = RAW_DIR / \"metadata\"\n",
    "if not METADATA_DIR.exists():\n",
    "    METADATA_DIR.mkdir(parents=True)\n",
    "\n",
    "METADATA_SOURCE = (\n",
    "    \"https://www.data.gouv.fr/fr/datasets/r/1fe544d8-4615-4642-a307-5956a7d90922\"\n",
    ")\n",
    "\n",
    "r = requests.get(METADATA_SOURCE)\n",
    "with open(METADATA_DIR / \"metadata.geojson\", \"wb\") as f:\n",
    "    f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Department Shapes\n",
    "\n",
    "[Source Page](https://france-geojson.gregoiredavid.fr/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEP_DIR = RAW_DIR / \"departments_shape\"\n",
    "if not DEP_DIR.exists():\n",
    "    DEP_DIR.mkdir(parents=True)\n",
    "\n",
    "DEP_SOURCE = \"https://france-geojson.gregoiredavid.fr/repo/departements.geojson\"\n",
    "\n",
    "r = requests.get(DEP_SOURCE)\n",
    "with open(DEP_DIR / \"departments.geojson\", \"wb\") as f:\n",
    "    f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "if not PROCESSED_DIR.exists():\n",
    "    PROCESSED_DIR.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extract all stations and their metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>department_id</th>\n",
       "      <th>altitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014002</td>\n",
       "      <td>ARBENT</td>\n",
       "      <td>1</td>\n",
       "      <td>534</td>\n",
       "      <td>46.278167</td>\n",
       "      <td>5.669000</td>\n",
       "      <td>ARBENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027003</td>\n",
       "      <td>BALAN_AERO</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>45.833000</td>\n",
       "      <td>5.106667</td>\n",
       "      <td>BALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028001</td>\n",
       "      <td>BANEINS</td>\n",
       "      <td>1</td>\n",
       "      <td>243</td>\n",
       "      <td>46.122000</td>\n",
       "      <td>4.904500</td>\n",
       "      <td>BANEINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1033002</td>\n",
       "      <td>BELLEGARDE</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>46.086500</td>\n",
       "      <td>5.814167</td>\n",
       "      <td>VALSERHONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1034004</td>\n",
       "      <td>BELLEY</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>45.769333</td>\n",
       "      <td>5.688000</td>\n",
       "      <td>BELLEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_name  department_id  altitude   latitude  longitude  \\\n",
       "0     1014002       ARBENT              1       534  46.278167   5.669000   \n",
       "1     1027003   BALAN_AERO              1       196  45.833000   5.106667   \n",
       "2     1028001      BANEINS              1       243  46.122000   4.904500   \n",
       "3     1033002   BELLEGARDE              1       350  46.086500   5.814167   \n",
       "4     1034004       BELLEY              1       330  45.769333   5.688000   \n",
       "\n",
       "         city  \n",
       "0      ARBENT  \n",
       "1       BALAN  \n",
       "2     BANEINS  \n",
       "3  VALSERHONE  \n",
       "4      BELLEY  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/raw/metadata/metadata.geojson\", \"r\") as f:\n",
    "    station_metadata = json.load(f)\n",
    "\n",
    "station_metadata = pd.json_normalize(\n",
    "    [v for _, v in station_metadata[\"features\"].items()]\n",
    ")\n",
    "station_metadata_variables = {\n",
    "    \"properties.NUM_POSTE\": \"station_id\",\n",
    "    \"properties.NOM_USUEL\": \"station_name\",\n",
    "    \"properties.NUM_DEP\": \"department_id\",\n",
    "    \"properties.ALTI\": \"altitude\",\n",
    "    \"properties.LAT_DG\": \"latitude\",\n",
    "    \"properties.LON_DG\": \"longitude\",\n",
    "    \"properties.COMMUNE\": \"city\",\n",
    "}\n",
    "station_metadata = station_metadata[station_metadata_variables.keys()]\n",
    "station_metadata = station_metadata.rename(columns=station_metadata_variables)\n",
    "station_metadata[\"station_id\"] = station_metadata[\"station_id\"].astype(int)\n",
    "station_metadata.to_csv(PROCESSED_DIR / \"station_metadata.csv\", index=False)\n",
    "station_metadata.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Time Series Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_RR = pd.read_csv(\"../data/raw/LSH/list/list_RR.csv\", sep=\";\", header=2)\n",
    "list_TN = pd.read_csv(\"../data/raw/LSH/list/list_TN.csv\", sep=\";\", header=2)\n",
    "list_TX = pd.read_csv(\"../data/raw/LSH/list/list_TX.csv\", sep=\";\", header=2)\n",
    "\n",
    "\n",
    "def filter_df_list(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    col_to_keep = [\"nom_fichier\", \"num_poste\"]\n",
    "    df = df[col_to_keep]\n",
    "    df.rename(\n",
    "        columns={\"nom_fichier\": \"file_name\", \"num_poste\": \"station_id\"}, inplace=True\n",
    "    )\n",
    "    df[\"variable\"] = name\n",
    "    return df\n",
    "\n",
    "\n",
    "list_RR = filter_df_list(list_RR, \"RR\")\n",
    "list_TN = filter_df_list(list_TN, \"TN\")\n",
    "list_TX = filter_df_list(list_TX, \"TX\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1034004</td>\n",
       "      <td>RR</td>\n",
       "      <td>SH_MRR101034004.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1072001</td>\n",
       "      <td>RR</td>\n",
       "      <td>SH_MRR101072001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089001</td>\n",
       "      <td>RR</td>\n",
       "      <td>SH_MRR101089001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1143002</td>\n",
       "      <td>RR</td>\n",
       "      <td>SH_MRR101143002.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1235001</td>\n",
       "      <td>RR</td>\n",
       "      <td>SH_MRR001235001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>91103001</td>\n",
       "      <td>TX</td>\n",
       "      <td>SH_MTX291103001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>91184001</td>\n",
       "      <td>TX</td>\n",
       "      <td>SH_MTX091184001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>94068001</td>\n",
       "      <td>TX</td>\n",
       "      <td>SH_MTX394068001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>95078001</td>\n",
       "      <td>TX</td>\n",
       "      <td>SH_MTX295078001.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>95088001</td>\n",
       "      <td>TX</td>\n",
       "      <td>SH_MTX395088001.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1471 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id variable            file_name\n",
       "0        1034004       RR  SH_MRR101034004.csv\n",
       "1        1072001       RR  SH_MRR101072001.csv\n",
       "2        1089001       RR  SH_MRR101089001.csv\n",
       "3        1143002       RR  SH_MRR101143002.csv\n",
       "4        1235001       RR  SH_MRR001235001.csv\n",
       "...          ...      ...                  ...\n",
       "1466    91103001       TX  SH_MTX291103001.csv\n",
       "1467    91184001       TX  SH_MTX091184001.csv\n",
       "1468    94068001       TX  SH_MTX394068001.csv\n",
       "1469    95078001       TX  SH_MTX295078001.csv\n",
       "1470    95088001       TX  SH_MTX395088001.csv\n",
       "\n",
       "[1471 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = pd.concat([list_RR, list_TN, list_TX])\n",
    "df_list = df_list[[\"station_id\", \"variable\", \"file_name\"]]\n",
    "df_list = df_list.reset_index()\n",
    "df_list.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "df_list.to_csv(PROCESSED_DIR / \"aggregated_list.csv\", index=True)\n",
    "df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_row(row: pd.Series) -> pd.DataFrame:\n",
    "    station_id = row[\"station_id\"]\n",
    "    variable = row[\"variable\"]\n",
    "    file_name = row[\"file_name\"]\n",
    "\n",
    "    if variable == \"IN\":\n",
    "        header = 11\n",
    "    else:\n",
    "        header = 12\n",
    "\n",
    "    df = pd.read_csv(LSH_DIR / variable / file_name, sep=\";\", header=header)\n",
    "    df = df[[\"YYYYMM\", \"VALEUR\"]]\n",
    "    df.columns = [\"timestamp\", \"value\"]\n",
    "    df[\"station_id\"] = station_id\n",
    "    df[\"variable\"] = variable\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83620/1611672627.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  measurements = pd.concat([measurements, row_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>station_id</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195101</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1034004</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195102</td>\n",
       "      <td>134.4</td>\n",
       "      <td>1034004</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195103</td>\n",
       "      <td>135.3</td>\n",
       "      <td>1034004</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195104</td>\n",
       "      <td>76.6</td>\n",
       "      <td>1034004</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195105</td>\n",
       "      <td>129.9</td>\n",
       "      <td>1034004</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  value station_id variable\n",
       "0    195101   83.0    1034004       RR\n",
       "1    195102  134.4    1034004       RR\n",
       "2    195103  135.3    1034004       RR\n",
       "3    195104   76.6    1034004       RR\n",
       "4    195105  129.9    1034004       RR"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = pd.DataFrame(columns=[\"timestamp\", \"value\", \"station_id\", \"variable\"])\n",
    "for row in df_list.iterrows():\n",
    "    row_df = process_list_row(row[1])\n",
    "    measurements = pd.concat([measurements, row_df], ignore_index=True)\n",
    "measurements.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>station_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315778</th>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>35238003</td>\n",
       "      <td>RR</td>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316714</th>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>35281001</td>\n",
       "      <td>RR</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317650</th>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>35294001</td>\n",
       "      <td>RR</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395699</th>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>44015001</td>\n",
       "      <td>RR</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397499</th>\n",
       "      <td>1945-01-01</td>\n",
       "      <td>44067001</td>\n",
       "      <td>RR</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004584</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>95078001</td>\n",
       "      <td>TN</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234011</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>95078001</td>\n",
       "      <td>TX</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785711</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>95088001</td>\n",
       "      <td>RR</td>\n",
       "      <td>55.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005424</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>95088001</td>\n",
       "      <td>TN</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234851</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>95088001</td>\n",
       "      <td>TX</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234852 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp station_id variable  value\n",
       "315778  1945-01-01   35238003       RR   65.6\n",
       "316714  1945-01-01   35281001       RR   69.8\n",
       "317650  1945-01-01   35294001       RR   64.0\n",
       "395699  1945-01-01   44015001       RR   64.5\n",
       "397499  1945-01-01   44067001       RR   64.3\n",
       "...            ...        ...      ...    ...\n",
       "1004584 2022-12-01   95078001       TN    2.2\n",
       "1234011 2022-12-01   95078001       TX    7.3\n",
       "785711  2022-12-01   95088001       RR   55.4\n",
       "1005424 2022-12-01   95088001       TN    2.9\n",
       "1234851 2022-12-01   95088001       TX    7.6\n",
       "\n",
       "[1234852 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = measurements[[\"timestamp\", \"station_id\", \"variable\", \"value\"]]\n",
    "measurements = measurements.sort_values([\"timestamp\", \"station_id\", \"variable\"])\n",
    "measurements[\"timestamp\"] = pd.to_datetime(measurements[\"timestamp\"], format=\"%Y%m\")\n",
    "measurements[\"station_id\"] = measurements[\"station_id\"].astype(str)\n",
    "measurements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Store data to a SQLite instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2394"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "if (DATA_DIR / \"data.db\").exists():\n",
    "    (DATA_DIR / \"data.db\").unlink()\n",
    "\n",
    "conn = sqlite3.connect(DATA_DIR / \"data.db\")\n",
    "measurements.to_sql(\n",
    "    \"measurements\", conn, if_exists=\"fail\", index=True, index_label=\"id\"\n",
    ")\n",
    "station_metadata.to_sql(\n",
    "    \"stations\", conn, if_exists=\"fail\", index=True, index_label=\"id\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccif-d3js-YnkgViM3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
